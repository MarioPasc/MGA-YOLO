# MGA-YOLO Configuration

# Model and Data
model_cfg: yolov8n.pt
data_yaml: /home/mpascual/research/datasets/angio/YOLO_MGA/detection/yolo_ica_detection.yaml
masks_dir: /home/mpascual/research/datasets/angio/YOLO_MGA/masks

# Training Parameters
epochs: 100
imgsz: 512
batch: 4
device: cuda:0
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
save_period: 10
iou: 0.5
single_cls: true

# MGA-specific Parameters
target_layers: 
  - "15"  # P3 layer
  - "18"  # P4 layer
  - "21"  # P5 layer
reduction_ratio: 16
kernel_size: 7
# How do we combine the spatial and channel attention maps?
# 1. add: Add the attention map to the original feature map: MGA = Att_spatial + Att_channel
# 2. multiply: Multiply the attention map with the original feature map: MGA = Att_spatial * Att_channel
sam_cam_fusion: "add"
# How do we combine the MGA output and the original feature maps?
mga_pyramid_fusion: "add"

# Experiment Settings
project: /home/mpascual/research/tests/YOLO_MGA/performance
name: experiment
visualize_features: true

# Augmentation Settings
augmentation_config:
  hsv_h: 0.0
  hsv_s: 0.0
  hsv_v: 0.0
  degrees: 0.0
  translate: 0.0
  scale: 0.0
  shear: 0.0
  perspective: 0.0
  flipud: 0.0
  fliplr: 0.0
  mosaic: 0.0
  mixup: 0.0