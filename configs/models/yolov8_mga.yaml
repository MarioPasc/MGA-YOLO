# MGA-YOLO custom architecture YAML (placeholder implementation)
# This file extends a standard YOLOv8 style detection model by inserting
# per-scale mask (segmentation) heads and Mask-Guided Attention (MGA) refinement
# modules at the P3, P4 and P5 feature map levels before the final Detect head.
#
# NOTE:
# - Custom modules referenced here (MGAMaskHead, MGAAttention) are NOT yet
#   implemented. They are placeholders so the architecture definition is laid out.
# - When you implement these modules, ensure they accept the shapes indicated
#   and return tensors compatible with the downstream Detect head.
# - The Detect head here still performs only object detection. A future custom
#   joint detection+segmentation head (e.g. MGADetect or MGASegment) could replace
#   it once mask fusion / decoding is implemented.
#
# Conventions:
#   [from, repeats, module, args]
#   'from' can be an int (single input) or list of layer indices (multiple inputs)
#   'repeats' is depth-scaled by the 'depth' scale factor
#   'args' are passed to the module __init__
#
# Parameters
nc: 80            # number of detection classes
# (Optional future) nm: 32   # number of prototype / mask channels if a proto head is later added
scales:           # model compound scaling constants, i.e. model=yolov8_mgan.yaml would select scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024]
  s: [0.50, 0.50, 1024]
  m: [0.50, 1.00, 512]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.50, 512]

# Backbone (copied from YOLOv8 baseline)
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9

# Neck / FPN + MGA extensions
head:
  # Standard top-down path
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]        # cat backbone P4
  - [-1, 2, C3k2, [512, False]]      # 13

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]        # cat backbone P3
  - [-1, 2, C3k2, [256, False]]      # 16 (P3)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]       # cat head P4
  - [-1, 2, C3k2, [512, False]]      # 19 (P4)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]       # cat head P5
  - [-1, 2, C3k2, [1024, True]]      # 22 (P5)

  # ----------------------------------------------------------------------
  # MGA ADDITIONS (placeholders)
  # For each scale (P3=16, P4=19, P5=22) we:
  #   1. Predict a scale-specific segmentation mask (or mask features) via MGAMaskHead
  #   2. Apply a mask-guided attention refinement MGAAttention that takes
  #      (feature, mask) -> refined feature used for detection
  # Indices:
  #   23: P3 mask, 24: P3 refined feature
  #   25: P4 mask, 26: P4 refined feature
  #   27: P5 mask, 28: P5 refined feature
  - [16, 1, MGAMaskHead, [256, 64]]          # 23 mask head for P3 (out channels placeholder 64)
  - [[16, 23], 1, MGAAttention, [256]]       # 24 refined P3 feature
  - [19, 1, MGAMaskHead, [512, 128]]         # 25 mask head for P4
  - [[19, 25], 1, MGAAttention, [512]]       # 26 refined P4 feature
  - [22, 1, MGAMaskHead, [1024, 256]]        # 27 mask head for P5
  - [[22, 27], 1, MGAAttention, [1024]]      # 28 refined P5 feature

  # (Optional future) multi-scale mask fusion head could go here.
  # - [[23,25,27], 1, MGAMaskFusion, [nc]]   # produce final fused mask logits (not yet implemented)

  # Final detection head now consumes refined features (24,26,28)
  - [[24, 26, 28], 1, Detect, [nc]]          # 29 Detect(P3, P4, P5)
