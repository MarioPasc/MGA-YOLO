# MGA-YOLO custom architecture YAML (placeholder implementation)
# This file extends a standard YOLOv8 style detection model by inserting
# per-scale mask (segmentation) heads and Mask-Guided Attention (MGA) refinement
# modules at the P3, P4 and P5 feature map levels before the final Detect head.
#
# NOTE:
# - Custom modules referenced here (MGAMaskHead, MGAAttention) are NOT yet
#   implemented. They are placeholders so the architecture definition is laid out.
# - When you implement these modules, ensure they accept the shapes indicated
#   and return tensors compatible with the downstream Detect head.
# - The Detect head here still performs only object detection. A future custom
#   joint detection+segmentation head (e.g. MGADetect or MGASegment) could replace
#   it once mask fusion / decoding is implemented.
#
# Conventions:
#   [from, repeats, module, args]
#   'from' can be an int (single input) or list of layer indices (multiple inputs)
#   'repeats' is depth-scaled by the 'depth' scale factor
#   'args' are passed to the module __init__
#
# Parameters
nc: 80            # number of detection classes
# (Optional future) nm: 32   # number of prototype / mask channels if a proto head is later added
scales:           # model compound scaling constants, i.e. model=yolov8_mgan.yaml would select scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024]
  s: [0.50, 0.50, 1024]
  m: [0.50, 1.00, 512]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.50, 512]

# Backbone (copied from YOLOv8 baseline)
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9

# Neck / FPN + MGA extensions
head:
  # Standard top-down path (mirrors baseline YOLOv8 so indices align with reference docs)
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]        # 12

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]        # 15 (P3)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]] # cat head P4
  - [-1, 3, C2f, [512]]        # 18 (P4)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]       # 21 (P5)

  # MGA mask heads (added AFTER feature-extracting C2f blocks so Detect indices unchanged)
  # NOTE: Using explicit in_channels values for 'n' scale (64,128,256). For larger scales adjust or
  # extend parse_model to auto-infer. Args: [in_channels, hidden_channels, out_channels]
  - [15, 1, MGAMaskHead, [64, 32, 1]]    # 22: P3 mask head
  - [18, 1, MGAMaskHead, [128, 64, 1]]   # 23: P4 mask head
  - [21, 1, MGAMaskHead, [256, 128, 1]]  # 24: P5 mask head

  # Final Detect uses original P3, P4, P5 feature maps (15,18,21)
  - [[15, 18, 21], 1, Detect, [nc]]    # 25 Detect(P3, P4, P5)
